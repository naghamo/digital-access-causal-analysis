{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import data_loader as dl\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "import pandas as pd\n",
    "import dowhy\n",
    "from dowhy import CausalModel\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tableone import TableOne"
   ],
   "id": "868d6ff33eb3a257",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "random_seed= 42",
   "id": "455351ada9a3c36d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "df= dl.load_data()\n",
    "df.head()"
   ],
   "id": "b33ef1c3e2b8912d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#save df as csv\n",
    "df.to_csv('cleand_df2018.csv', index=False)"
   ],
   "id": "a97b0c3021a8c038",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(df['book'].unique())\n",
    "print(df['math'].min(), df['math'].max())\n",
    "print(df['read'].min(), df['read'].max())\n",
    "print(df['science'].min(), df['science'].max())\n",
    "print(df['achievement'].min(), df['achievement'].max())\n",
    "\n"
   ],
   "id": "6c0c4f285323b6ae",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "treatment = \"computer\"\n",
    "outcome = \"achievement\"\n",
    "\n",
    "country_cols = [col for col in df.columns if col.startswith(\"country_\")]\n",
    "\n",
    "\n",
    "edges = [\n",
    "    \"computer -> achievement;\",\n",
    "    \"escs -> computer;\", \"escs -> achievement;\",\n",
    "    \"mother_educ -> computer;\", \"mother_educ -> achievement;\",\n",
    "    \"father_educ -> computer;\", \"father_educ -> achievement;\",\n",
    "    \"desk -> computer;\", \"desk -> achievement;\",\n",
    "    \"room -> computer;\", \"room -> achievement;\",\n",
    "    \"book -> computer;\", \"book -> achievement;\",\n",
    "    \"gender -> computer;\", \"gender -> achievement;\"\n",
    "]\n",
    "\n",
    "\n",
    "for country_col in country_cols:\n",
    "    edges.append(f\"{country_col} -> computer;\")\n",
    "    edges.append(f\"{country_col} -> achievement;\")\n",
    "\n",
    "\n",
    "graph_str = \"digraph {\\n\" + \"\\n\".join(edges) + \"\\n}\"\n",
    "\n",
    "\n",
    "confounders = [\n",
    "    'escs', 'mother_educ', 'father_educ', 'desk', 'room', 'book', 'gender'\n",
    "] + country_cols\n",
    "\n",
    "print(graph_str)\n",
    "\n",
    "# , \"wealth\""
   ],
   "id": "d9f2ebace1841d4b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# # graph_str = \"digraph {computer -> achievement; escs -> computer; escs -> achievement; mother_educ -> computer; mother_educ -> achievement; father_educ -> computer; father_educ -> achievement; desk -> computer; desk -> achievement; room -> computer; room -> achievement; book -> computer; book -> achievement; gender -> computer; gender -> achievement; country -> computer; country -> achievement;}\"\n",
    "#\n",
    "#\n",
    "# graph_str = \"digraph { computer -> achievement; }\"\n",
    "#\n",
    "# # Debug: print columns to check for typos\n",
    "# print(\"Columns in df:\", df.columns.tolist())\n",
    "#\n",
    "# # Create the CausalModel\n",
    "# model = CausalModel(\n",
    "#     data=df,\n",
    "#     treatment=treatment,\n",
    "#     outcome=outcome,\n",
    "#     common_causes=confounders,\n",
    "#     graph=graph_str\n",
    "# )\n",
    "#\n",
    "# model.view_model()\n",
    "#\n",
    "# # Identify estimand\n",
    "# identified_estimand = model.identify_effect()\n",
    "# print(\"Identified estimand:\\n\", identified_estimand)\n",
    "#\n",
    "# # Estimate causal effect with two methods\n",
    "# causal_estimate_lr = model.estimate_effect(\n",
    "#     identified_estimand,\n",
    "#     method_name=\"backdoor.linear_regression\"\n",
    "# )\n",
    "# print(\"Linear regression estimate:\", causal_estimate_lr.value)\n",
    "#\n",
    "# causal_estimate_ps = model.estimate_effect(\n",
    "#     identified_estimand,\n",
    "#     method_name=\"backdoor.propensity_score_stratification\"\n",
    "# )\n",
    "# print(\"Propensity score stratification estimate:\", causal_estimate_ps.value)\n",
    "#\n",
    "# # Robustness checks: Placebo, dummy outcome, random confounder, hidden confounder\n",
    "# placebo = model.refute_estimate(\n",
    "#     identified_estimand,\n",
    "#     causal_estimate_lr,\n",
    "#     method_name=\"placebo_treatment_refuter\"\n",
    "# )\n",
    "# print(\"Placebo treatment refutation:\\n\", placebo)\n",
    "#\n",
    "# dummy = model.refute_estimate(\n",
    "#     identified_estimand,\n",
    "#     causal_estimate_lr,\n",
    "#     method_name=\"dummy_outcome_refuter\"\n",
    "# )\n",
    "# print(\"Dummy outcome refutation:\\n\", dummy)\n",
    "#\n",
    "# random_confounder = model.refute_estimate(\n",
    "#     identified_estimand,\n",
    "#     causal_estimate_lr,\n",
    "#     method_name=\"random_common_cause\"\n",
    "# )\n",
    "# print(\"Random common cause refutation:\\n\", random_confounder)\n",
    "#\n",
    "# unobserved = model.refute_estimate(\n",
    "#     identified_estimand,\n",
    "#     causal_estimate_lr,\n",
    "#     method_name=\"add_unobserved_common_cause\"\n",
    "# )\n",
    "# print(\"Unobserved confounder simulation:\\n\", unobserved)\n"
   ],
   "id": "29159990e7dd430d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "X=df[confounders]\n",
    "y=df[outcome]\n",
    "T=df[treatment]\n"
   ],
   "id": "aa32b47b02225098",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "X_train, X_val, T_train, T_val, y_train, y_val = train_test_split(X, T, y, test_size=0.3, random_state=random_seed)",
   "id": "7183f11b7292c1a4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.calibration import calibration_curve\n",
    "from sklearn.metrics import brier_score_loss\n",
    "import matplotlib.pyplot as plt\n",
    "def train_propensity_model(model, X_train, T_train):\n",
    "    \"\"\"\n",
    "    Return a fitted propensity model on your training data\n",
    "    :param model:\n",
    "    :param X_train:\n",
    "    :param T_train:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    return model.fit(X_train, T_train)\n",
    "\n",
    "def eval_propensity_model(fitted_model, X_val, T_val,model_name=\"Propensity Model\"):\n",
    "    \"\"\"\n",
    "    Check your fitted propensity model using the brier score and calibration curve.\n",
    "\n",
    "    You must print or return (and then print for us to see) the brier score.\n",
    "    You must show the calibration curve.\n",
    "    :param fitted_model:\n",
    "    :param X_val:\n",
    "    :param T_val:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    # Get the predicted probabilities\n",
    "    y_pred = fitted_model.predict_proba(X_val)[:, 1]\n",
    "\n",
    "    # Calculate the Brier score\n",
    "    brier_score = brier_score_loss(T_val, y_pred)\n",
    "    print('' + model_name + ' evaluation:')\n",
    "    # Print the Brier score\n",
    "    print(f'Brier score: {brier_score}')\n",
    "\n",
    "    # Plot the calibration curve\n",
    "    prob_true, prob_pred = calibration_curve(T_val, y_pred, n_bins=10)\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(prob_pred, prob_true, marker='o', label='Calibration curve')\n",
    "    plt.plot([0, 1], [0, 1], linestyle='--', label='Perfectly calibrated')\n",
    "    plt.xlabel('Mean predicted probability')\n",
    "    plt.ylabel('Fraction of positives')\n",
    "    plt.title('Calibration curve')\n",
    "    plt.legend()\n",
    "    plt.show()\n"
   ],
   "id": "7741f698f2372537",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, ExtraTreesClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score, brier_score_loss, accuracy_score,\n",
    "    log_loss, f1_score, precision_score, recall_score\n",
    ")\n",
    "from sklearn.calibration import calibration_curve\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Add more models as needed\n",
    "models = {\n",
    "    \"Logistic Regression CV\": LogisticRegressionCV(cv=5, max_iter=1000, random_state=random_seed),\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=100, max_depth=5, random_state=random_seed),\n",
    "    \"Extra Trees\": ExtraTreesClassifier(n_estimators=100, random_state=random_seed),\n",
    "    \"XGBoost\": XGBClassifier(n_estimators=100, max_depth=3, learning_rate=0.1, use_label_encoder=False, eval_metric='logloss', random_state=random_seed),\n",
    "    \"Gradient Boosting\": GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, random_state=random_seed),\n",
    "    \"LightGBM\": LGBMClassifier(n_estimators=100, max_depth=3, random_state=random_seed),\n",
    "    \"CatBoost\": CatBoostClassifier(iterations=100, depth=3, learning_rate=0.1, verbose=0, random_state=random_seed),\n",
    "    # \"MLP Classifier\": MLPClassifier(hidden_layer_sizes=(64,32), max_iter=300, random_state=random_seed),\n",
    "\n",
    "}\n",
    "\n",
    "results = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, T_train)\n",
    "    probas = model.predict_proba(X_val)[:, 1]\n",
    "    preds = model.predict(X_val)\n",
    "    auc = roc_auc_score(T_val, probas)\n",
    "    brier = brier_score_loss(T_val, probas)\n",
    "    acc = accuracy_score(T_val, preds)\n",
    "    ll = log_loss(T_val, probas)\n",
    "    f1 = f1_score(T_val, preds)\n",
    "    precision = precision_score(T_val, preds)\n",
    "    recall = recall_score(T_val, preds)\n",
    "    results[name] = {\n",
    "        'Brier': brier\n",
    "        }\n",
    "    print(f\"{name}:  Brier={brier:.4f}\")\n",
    "\n",
    "df_results = pd.DataFrame(results).T\n",
    "print(\"\\nAll results:\\n\", df_results)\n",
    "\n",
    "# Find best model for each metric\n",
    "\n",
    "best_brier_model = df_results['Brier'].idxmin()\n",
    "\n",
    "\n",
    "\n",
    "print(f\"Best model by Brier: {best_brier_model} ({df_results.loc[best_brier_model, 'Brier']:.4f})\")\n",
    "\n",
    "# Save the best model by AUC (change metric as needed)\n",
    "best_model = models[best_brier_model]\n",
    "# Calibration curve for the best model by AUC\n",
    "probas = best_model.predict_proba(X_val)[:, 1]\n",
    "from sklearn.calibration import calibration_curve\n",
    "prob_true, prob_pred = calibration_curve(T_val, probas, n_bins=10)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(prob_pred, prob_true, marker='o', label='Calibration curve')\n",
    "plt.plot([0, 1], [0, 1], linestyle='--', label='Perfectly calibrated')\n",
    "plt.xlabel('Mean predicted probability')\n",
    "plt.ylabel('Fraction of positives')\n",
    "plt.title(f'Calibration curve ({best_brier_model})')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ],
   "id": "7148be08fcf8aafd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def check_overlap(propensity_model, X_train, T_train,\n",
    "                  show_limits=False,limit_low=0.03, limit_high=0.76):\n",
    "    \"\"\"\n",
    "    Show histograms of the propensity on the T=0 and the T=1 group like in the tutorial\n",
    "    Use this to ascertain if there is a violation of overlap.\n",
    "\n",
    "    You must show the graph.\n",
    "    :param propensity_model:\n",
    "    :param X_train:\n",
    "    :param T_train:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    # Get the predicted probabilities\n",
    "    y_pred = propensity_model.predict_proba(X_train)[:, 1]\n",
    "\n",
    "    # Create histograms for T=0 and T=1\n",
    "    plt.figure(figsize=(10, 6))\n",
    "\n",
    "    sns.histplot(y_pred[T_train == 1], color='red', label='Treated (Has Computer)', bins=30, stat=\"density\", alpha=0.6)\n",
    "    sns.histplot(y_pred[T_train == 0], color='blue', label='Control (No Computer)', bins=30, stat=\"density\", alpha=0.6)\n",
    "\n",
    "    plt.xlabel('Predicted Probability of Treatment')\n",
    "    plt.ylabel('Density')\n",
    "    plt.title('Overlap Check: Predicted Probabilities for T=0 and T=1')\n",
    "    if show_limits:\n",
    "        plt.axvline(limit_low, color='red', linestyle='--', label=f'Threshold ({limit_low})')\n",
    "        plt.axvline(limit_high, color='red', linestyle='--', label=f'Threshold ({limit_high})')\n",
    "\n",
    "    plt.legend()\n",
    "    plt.show()\n"
   ],
   "id": "302da5895dd1af68",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "check_overlap(best_model, X_train, T_train)",
   "id": "6e2c74f999ff1f61",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def trim_by_propensity(X, y, T, propensity_scores, lower=0.05, upper=0.95):\n",
    "    mask = (propensity_scores >= lower) & (propensity_scores <= upper)\n",
    "    X_trim = X[mask]\n",
    "    y_trim = y[mask]\n",
    "    T_trim = T[mask]\n",
    "    propensity_scores_trim = propensity_scores[mask]\n",
    "    print(f\"Trimmed to {mask.sum()} samples (from {len(mask)}) in [{lower}, {upper}] region.\")\n",
    "    return X_trim, y_trim, T_trim, propensity_scores_trim\n",
    "\n",
    "propensity_scores = best_model.predict_proba(X)[:, 1]\n",
    "\n",
    "# Trim the data\n",
    "X_trim, y_trim, T_trim, propensity_scores_trim = trim_by_propensity(\n",
    "    X, y, T, propensity_scores, lower=0.05, upper=0.95\n",
    ")"
   ],
   "id": "b0a2eaaaca919ebb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "X_train, X_val, T_train, T_val, y_train, y_val = train_test_split(X_trim, T_trim, y_trim, test_size=0.3, random_state=random_seed)",
   "id": "c6229adcb2a97c3e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "T-learner",
   "id": "b58f3e77b5e2e825"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, ExtraTreesRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import (\n",
    "    mean_squared_error\n",
    ")\n",
    "from sklearn.base import clone\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "\n",
    "def train_t_learner(model, X_train, y_train):\n",
    "    return model.fit(X_train, y_train)\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "def t_learner_model_selection(models, X_train, y_train, X_val, y_val):\n",
    "    metrics = {\n",
    "        \"RMSE\": lambda y_true, y_pred: mean_squared_error(y_true, y_pred),  # RMSE = sqrt(MSE)\n",
    "    }\n",
    "    results = {name: {} for name in [m.__class__.__name__ for m in models]}\n",
    "    best_models = {}\n",
    "\n",
    "    for metric_name, metric_func in tqdm(metrics.items(), desc=\"Metrics\"):\n",
    "        best_score = np.inf if metric_name in [\"RMSE\"] else -np.inf\n",
    "        best_model = None\n",
    "\n",
    "        for model in tqdm(models, desc=f\"Models for {metric_name}\", leave=False):\n",
    "            fitted_model = train_t_learner(clone(model), X_train, y_train)\n",
    "            y_pred = fitted_model.predict(X_val)\n",
    "            score = metric_func(y_val, y_pred)\n",
    "            results[model.__class__.__name__][metric_name] = score\n",
    "\n",
    "            is_better = (score < best_score) if metric_name in [\"RMSE\"] else (score > best_score)\n",
    "            if is_better:\n",
    "                best_score = score\n",
    "                best_model = fitted_model\n",
    "\n",
    "        best_models[metric_name] = best_model\n",
    "        print(f'Best model for {metric_name}: {best_model.__class__.__name__} with score {best_score:.4f}')\n",
    "\n",
    "    # Display results table\n",
    "    df_results = pd.DataFrame(results).T\n",
    "    print(\"\\nAll validation scores:\")\n",
    "    print(df_results)\n",
    "\n",
    "    for metric_name in metrics:\n",
    "        print(f\"Best model by {metric_name}: {best_models[metric_name].__class__.__name__} (Score: {df_results[metric_name][best_models[metric_name].__class__.__name__]:.4f})\")\n",
    "\n",
    "    # Save best model by RMSE as example\n",
    "    joblib.dump(best_models[\"RMSE\"], \"best_t_learner_model_rmse.pkl\")\n",
    "    print(f\"\\nSaved best T-learner model (by RMSE): {best_models['RMSE'].__class__.__name__}\")\n",
    "\n",
    "    return best_models  # dict: metric_name -> best fitted model\n",
    "# dict: metric_name -> best fitted model\n",
    "\n",
    "# Example usage:\n",
    "models = [\n",
    "    LinearRegression(),\n",
    "    Ridge(alpha=1.0),\n",
    "    Lasso(alpha=0.1),\n",
    "    RandomForestRegressor(n_estimators=100, max_depth=5, random_state=0),\n",
    "    GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, random_state=0),\n",
    "    # ExtraTreesRegressor(n_estimators=100, random_state=0),\n",
    "    XGBRegressor(n_estimators=100, max_depth=3, learning_rate=0.1, random_state=0),\n",
    "    LGBMRegressor(n_estimators=100, max_depth=3, random_state=0),\n",
    "    # MLPRegressor(hidden_layer_sizes=(64,32), max_iter=300, random_state=0)\n",
    "]\n",
    "\n",
    "# For treated arm (T=1)\n",
    "X_train_treated = X_train[T_train == 1]\n",
    "y_train_treated = y_train[T_train == 1]\n",
    "X_val_treated = X_val[T_val == 1]\n",
    "y_val_treated = y_val[T_val == 1]\n",
    "\n",
    "# For control arm (T=0)\n",
    "X_train_control = X_train[T_train == 0]\n",
    "y_train_control = y_train[T_train == 0]\n",
    "X_val_control = X_val[T_val == 0]\n",
    "y_val_control = y_val[T_val == 0]\n",
    "print(\"\\n=== Selecting model for T=1 (treated arm) ===\")\n",
    "best_models_treated = t_learner_model_selection(models, X_train_treated, y_train_treated, X_val_treated, y_val_treated)\n",
    "\n",
    "print(\"\\n=== Selecting model for T=0 (control arm) ===\")\n",
    "best_models_control = t_learner_model_selection(models, X_train_control, y_train_control, X_val_control, y_val_control)\n"
   ],
   "id": "e0c98bafc7363db3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "from sklearn.base import clone\n",
    "\n",
    "def calculate_t_learner_ate(model_treated, model_control, X):\n",
    "    \"\"\"\n",
    "    Estimate the Average Treatment Effect (ATE) using a fitted T-learner.\n",
    "\n",
    "    Args:\n",
    "        model_treated: Fitted model for treated (T=1) group.\n",
    "        model_control: Fitted model for control (T=0) group.\n",
    "        X: DataFrame of covariates to estimate potential outcomes on.\n",
    "\n",
    "    Returns:\n",
    "        ate (float): Estimated ATE on X.\n",
    "    \"\"\"\n",
    "    y1_pred = model_treated.predict(X)\n",
    "    y0_pred = model_control.predict(X)\n",
    "    ate = (y1_pred - y0_pred).mean()\n",
    "    print(f\"Estimated ATE (T-Learner): {ate:.4f}\")\n",
    "    return ate\n",
    "\n",
    "def t_learner_confidence_intervals(model_treated, model_control,\n",
    "                                   X_train, T_train, y_train,\n",
    "                                   X_pred, n_iterations=1000, alpha=0.05, random_seed=random_seed):\n",
    "    \"\"\"\n",
    "    Estimate a 95% bootstrap confidence interval for the T-learner ATE.\n",
    "\n",
    "    Args:\n",
    "        model_treated: Fitted model for T=1.\n",
    "        model_control: Fitted model for T=0.\n",
    "        X_train: Training features (DataFrame)\n",
    "        T_train: Treatment vector (Series or array)\n",
    "        y_train: Outcome vector (Series or array)\n",
    "        X_pred: Covariates to predict the ATE on (e.g., validation or full set)\n",
    "        n_iterations: Number of bootstrap samples.\n",
    "        alpha: Significance level (default=0.05 for 95% CI)\n",
    "        random_seed: Reproducibility.\n",
    "\n",
    "    Returns:\n",
    "        (lower, upper): Lower and upper bounds of the bootstrap CI.\n",
    "    \"\"\"\n",
    "    np.random.seed(random_seed)\n",
    "    ate_estimates = []\n",
    "\n",
    "    for _ in tqdm(range(n_iterations), desc=f\"iterations\"):\n",
    "        # Bootstrap sample indices\n",
    "        indices = np.random.choice(X_train.index, size=len(X_train), replace=True)\n",
    "        X_resampled = X_train.loc[indices]\n",
    "        T_resampled = T_train.loc[indices]\n",
    "        y_resampled = y_train.loc[indices]\n",
    "\n",
    "        # Split resampled data by treatment group\n",
    "        X1, y1 = X_resampled[T_resampled == 1], y_resampled[T_resampled == 1]\n",
    "        X0, y0 = X_resampled[T_resampled == 0], y_resampled[T_resampled == 0]\n",
    "\n",
    "        # Refit both models on bootstrap sample\n",
    "        model1 = clone(model_treated).fit(X1, y1)\n",
    "        model0 = clone(model_control).fit(X0, y0)\n",
    "\n",
    "        # Predict on X_pred\n",
    "        y1_pred = model1.predict(X_pred)\n",
    "        y0_pred = model0.predict(X_pred)\n",
    "        ate_estimates.append((y1_pred - y0_pred).mean())\n",
    "\n",
    "    # Calculate the confidence interval\n",
    "    lower = np.percentile(ate_estimates, 100 * alpha / 2)\n",
    "    upper = np.percentile(ate_estimates, 100 * (1 - alpha / 2))\n",
    "\n",
    "    print(f\"95% Confidence Interval for ATE (T-Learner): [{lower:.4f}, {upper:.4f}]\")\n",
    "    return lower, upper\n"
   ],
   "id": "85afdbcc540e5996",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "print(best_models_treated)",
   "id": "44fedac67be4a12f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "ate = calculate_t_learner_ate(best_models_treated['RMSE'], best_models_control['RMSE'], X_val)\n",
    "\n",
    "# Get confidence interval:\n",
    "t_learner_ci= t_learner_confidence_intervals(\n",
    "    best_models_treated['RMSE'], best_models_control['RMSE'],\n",
    "    X_train, T_train, y_train, X_val, n_iterations=1000, alpha=0.05, random_seed=random_seed\n",
    ")\n"
   ],
   "id": "952bd2560ac074d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "IPW",
   "id": "3a9ae44789afc56a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "\n",
    "def calculate_ipw_ate(propensity_scores, T, y):\n",
    "    \"\"\"\n",
    "    Estimate ATE using Inverse Probability Weighting (IPW).\n",
    "\n",
    "    Args:\n",
    "        propensity_scores: np.array or pd.Series of predicted propensities (P(T=1|X))\n",
    "        T: Treatment indicator (np.array or pd.Series, 0/1)\n",
    "        y: Outcome (np.array or pd.Series)\n",
    "\n",
    "    Returns:\n",
    "        ipw_ate (float): Estimated ATE\n",
    "    \"\"\"\n",
    "    epsilon = 1e-6\n",
    "    # ps = np.clip(propensity_scores, epsilon, 1 - epsilon)\n",
    "    weight_treated = T / propensity_scores\n",
    "    weight_control = (1 - T) / (1 - propensity_scores)\n",
    "\n",
    "    ipw_ate = np.mean(weight_treated * y) - np.mean(weight_control * y)\n",
    "    print(f\"Estimated ATE (IPW): {ipw_ate:.4f}\")\n",
    "    return ipw_ate\n"
   ],
   "id": "9815cbcbd515c227",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "propensity_scores_val = best_model.predict_proba(X_val)[:, 1]\n",
    "ipw_ate = calculate_ipw_ate(propensity_scores_val, T_val, y_val)\n",
    "print(f\"Estimated ATE using IPW: {ipw_ate:.4f}\")\n"
   ],
   "id": "a8a370baa648ff27",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from tqdm.auto import tqdm\n",
    "import numpy as np\n",
    "\n",
    "def ipw_confidence_intervals(model, X_val, T_val, y_val, n_iterations=1000, alpha=0.05, random_seed=random_seed, verbose=True):\n",
    "    \"\"\"\n",
    "    Bootstrap 95% confidence interval for IPW ATE.\n",
    "\n",
    "    Args:\n",
    "        model: fitted propensity model (must have predict_proba)\n",
    "        X_val: validation features (DataFrame)\n",
    "        T_val: validation treatment (Series)\n",
    "        y_val: validation outcome (Series)\n",
    "        n_iterations: number of bootstrap iterations (default 1000)\n",
    "        alpha: significance level (default 0.05 for 95% CI)\n",
    "        random_seed: random seed for reproducibility\n",
    "        verbose: whether to print the CI\n",
    "\n",
    "    Returns:\n",
    "        lower, upper: confidence interval for IPW ATE\n",
    "    \"\"\"\n",
    "    np.random.seed(random_seed)\n",
    "    ate_estimates = []\n",
    "    epsilon = 1e-6\n",
    "\n",
    "    for _ in tqdm(range(1000), desc=f\"IPW Bootstrap\"):\n",
    "        indices = np.random.choice(X_val.index, size=len(X_val), replace=True)\n",
    "        X_boot = X_val.loc[indices]\n",
    "        T_boot = T_val.loc[indices]\n",
    "        y_boot = y_val.loc[indices]\n",
    "\n",
    "        # Predict propensity scores and clip\n",
    "        p_scores = np.clip(model.predict_proba(X_boot)[:, 1], epsilon, 1 - epsilon)\n",
    "\n",
    "        # Compute IPW ATE for this sample\n",
    "        weights_treated = T_boot / p_scores\n",
    "        weights_control = (1 - T_boot) / (1 - p_scores)\n",
    "        ipw_ate = np.mean(weights_treated * y_boot) - np.mean(weights_control * y_boot)\n",
    "        ate_estimates.append(ipw_ate)\n",
    "\n",
    "    lower = np.percentile(ate_estimates, 100 * alpha / 2)\n",
    "    upper = np.percentile(ate_estimates, 100 * (1 - alpha / 2))\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"95% Confidence Interval for ATE (IPW): [{lower:.4f}, {upper:.4f}]\")\n",
    "    return lower, upper\n"
   ],
   "id": "5402ccef828268e3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "ipw_ci = ipw_confidence_intervals(best_model, X_val, T_val, y_val)\n",
   "id": "7c7d8ce814277f1f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "doubly robust",
   "id": "e912571014f3e64c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "\n",
    "def calculate_dr_ate(y, T, propensity_scores, mu0_pred, mu1_pred):\n",
    "    \"\"\"\n",
    "    Doubly Robust ATE Estimation.\n",
    "\n",
    "    Args:\n",
    "        y:      Observed outcome (array or Series)\n",
    "        T:      Treatment indicator (0/1, array or Series)\n",
    "        propensity_scores:  P(T=1|X), estimated propensity for each row\n",
    "        mu0_pred:  Predicted outcome if untreated (model.predict(X), for all X)\n",
    "        mu1_pred:  Predicted outcome if treated   (model.predict(X), for all X)\n",
    "\n",
    "    Returns:\n",
    "        dr_ate:  Estimated ATE (float)\n",
    "    \"\"\"\n",
    "    # Safety (avoid division by zero)\n",
    "    eps = 1e-6\n",
    "    propensity_scores = np.clip(propensity_scores, eps, 1-eps)\n",
    "\n",
    "    # Doubly Robust estimate:\n",
    "    dr_scores = (mu1_pred - mu0_pred) \\\n",
    "        + T * (y - mu1_pred) / propensity_scores \\\n",
    "        - (1 - T) * (y - mu0_pred) / (1 - propensity_scores)\n",
    "\n",
    "    dr_ate = np.mean(dr_scores)\n",
    "    print(f\"Estimated ATE (Doubly Robust): {dr_ate:.4f}\")\n",
    "    return dr_ate\n",
    "\n",
    "mu1_pred = best_models_treated['RMSE'].predict(X_trim)  # \"what if all treated\"\n",
    "mu0_pred = best_models_control['RMSE'].predict(X_trim)  # \"what if all control\"\n",
    "\n",
    "dr_ate = calculate_dr_ate(y_trim, T_trim, propensity_scores_trim, mu0_pred, mu1_pred)\n"
   ],
   "id": "31a0e11a875b9c2b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "from sklearn.base import clone\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "def dr_confidence_intervals(\n",
    "    X, y, T,\n",
    "    propensity_model, model_treated, model_control,\n",
    "    n_iterations=1000, alpha=0.05, random_seed=random_seed, verbose=True\n",
    "):\n",
    "    \"\"\"\n",
    "    Bootstrap 95% confidence interval for Doubly Robust ATE.\n",
    "\n",
    "    Args:\n",
    "        X: Features (DataFrame or array, already trimmed)\n",
    "        y: Outcome (Series/array, trimmed)\n",
    "        T: Treatment (Series/array, trimmed)\n",
    "        propensity_model: fitted propensity score model\n",
    "        model_treated: fitted outcome model for T=1\n",
    "        model_control: fitted outcome model for T=0\n",
    "        n_iterations: number of bootstrap samples (default 1000)\n",
    "        alpha: significance level (default 0.05 for 95% CI)\n",
    "        random_seed: for reproducibility\n",
    "        verbose: whether to print the CI\n",
    "\n",
    "    Returns:\n",
    "        (lower, upper): bounds of the confidence interval\n",
    "    \"\"\"\n",
    "    np.random.seed(random_seed)\n",
    "    ate_estimates = []\n",
    "    eps = 1e-6\n",
    "\n",
    "    for _ in tqdm(range(n_iterations), desc=\"DR Bootstrap\"):\n",
    "        # Sample with replacement\n",
    "        indices = np.random.choice(X.index, size=len(X), replace=True)\n",
    "        X_boot = X.loc[indices]\n",
    "        y_boot = y.loc[indices]\n",
    "        T_boot = T.loc[indices]\n",
    "\n",
    "        # Estimate propensity\n",
    "        p_scores = np.clip(propensity_model.predict_proba(X_boot)[:, 1], eps, 1-eps)\n",
    "\n",
    "        # Predict outcomes as if all treated / control\n",
    "        mu1_pred = model_treated.predict(X_boot)\n",
    "        mu0_pred = model_control.predict(X_boot)\n",
    "\n",
    "        # DR estimate\n",
    "        dr_scores = (mu1_pred - mu0_pred) \\\n",
    "            + T_boot * (y_boot - mu1_pred) / p_scores \\\n",
    "            - (1 - T_boot) * (y_boot - mu0_pred) / (1 - p_scores)\n",
    "        dr_ate = np.mean(dr_scores)\n",
    "        ate_estimates.append(dr_ate)\n",
    "\n",
    "    lower = np.percentile(ate_estimates, 100 * alpha / 2)\n",
    "    upper = np.percentile(ate_estimates, 100 * (1 - alpha / 2))\n",
    "    if verbose:\n",
    "        print(f\"95% Confidence Interval for ATE (Doubly Robust): [{lower:.4f}, {upper:.4f}]\")\n",
    "    return lower, upper\n",
    "# Everything after trimming (same indices/order!):\n",
    "dr_ci = dr_confidence_intervals(\n",
    "    X_trim, y_trim, T_trim,\n",
    "    propensity_model=best_model,      # your chosen/fitted propensity model\n",
    "    model_treated=best_models_treated['RMSE'],  # your best T=1 model\n",
    "    model_control=best_models_control['RMSE'],  # your best T=0 model\n",
    "    n_iterations=1000,\n",
    "    alpha=0.05,\n",
    "    random_seed=random_seed\n",
    ")\n"
   ],
   "id": "620f9dbe7da59455",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "matching",
   "id": "fc771650ad6f1c1c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "from tableone import TableOne\n",
    "\n",
    "T_train_named = T_train.copy()\n",
    "T_train_named.name = 'T'\n",
    "\n",
    "# Concatenate along columns, so 'T' is a column\n",
    "df_table = pd.concat([X_train, T_train_named], axis=1)\n",
    "\n",
    "# List the columns you want in the table\n",
    "columns = confounders\n",
    "\n",
    "table1 = TableOne(df_table, columns=columns, groupby='T', nonnormal=[], pval=False, smd=True)\n",
    "\n",
    "# Print the summary table\n",
    "print(table1.tabulate(tablefmt=\"fancy_grid\"))\n",
    "\n"
   ],
   "id": "6d8fd8d004ad9785",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def compute_smd(col, treated, control):\n",
    "    \"\"\"Compute standardized mean difference for a covariate.\"\"\"\n",
    "    mean_t, mean_c = treated[col].mean(), control[col].mean()\n",
    "    std_t, std_c = treated[col].std(), control[col].std()\n",
    "    pooled_std = np.sqrt((std_t ** 2 + std_c ** 2) / 2)\n",
    "    return abs(mean_t - mean_c) / pooled_std if pooled_std > 0 else 0\n",
    "\n",
    "def plot_smd_balance(data, covariates, treatment_col='T', threshold=0.1):\n",
    "    \"\"\"Plot SMD for covariates with a horizontal layout like in the tutorial.\"\"\"\n",
    "    treated = data[data[treatment_col] == 1]\n",
    "    control = data[data[treatment_col] == 0]\n",
    "\n",
    "    smd_scores = {\n",
    "        cov: compute_smd(cov, treated, control) for cov in covariates\n",
    "    }\n",
    "\n",
    "    # Sort covariates for better display\n",
    "    covs, scores = zip(*sorted(smd_scores.items(), key=lambda x: x[1], reverse=True))\n",
    "\n",
    "    # Plot horizontal bar chart\n",
    "    plt.figure(figsize=(8, 15))\n",
    "    plt.barh(covs, scores, color='skyblue')\n",
    "    plt.axvline(x=threshold, color='red', linestyle='--', label=f'Threshold = {threshold}')\n",
    "    plt.title(\"SMD for Covariates After Matching\")\n",
    "    plt.xlabel(\"Standardized Mean Difference (SMD)\")\n",
    "    plt.ylabel(\"Covariates\")\n",
    "    plt.legend()\n",
    "    plt.grid(True, axis='x')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_smd_balance(data=pd.concat([X_train, T_train], axis=1), covariates= confounders,treatment_col=treatment)"
   ],
   "id": "f372a154a2f7ac71",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Suppose after trimming:\n",
    "# X_trim, y_trim, T_trim, propensity_scores_trim\n",
    "df = pd.DataFrame(X_trim.copy())\n",
    "df['y'] = y_trim\n",
    "df['T'] = T_trim\n",
    "df['ps'] = propensity_scores_trim\n",
    "df = df.reset_index(drop=True)\n"
   ],
   "id": "6159b4715560a7ce",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "caliper = 0.05  # e.g., allow max 0.05 difference in propensity\n",
    "\n",
    "treated = df[df['T'] == 1].copy()\n",
    "control = df[df['T'] == 0].copy()\n",
    "\n",
    "# For each treated, find a control within caliper\n",
    "matched_treated_idx = []\n",
    "matched_control_idx = []\n",
    "\n",
    "nbrs = NearestNeighbors(n_neighbors=1, algorithm='ball_tree').fit(control[['ps']])\n",
    "\n",
    "for i, row in treated.iterrows():\n",
    "    dist, idx = nbrs.kneighbors([[row['ps']]])\n",
    "    if dist[0][0] <= caliper:\n",
    "        matched_treated_idx.append(i)\n",
    "        matched_control_idx.append(control.index[idx[0][0]])\n",
    "\n",
    "# Build matched dataset\n",
    "matched_df = pd.concat([\n",
    "    treated.loc[matched_treated_idx],\n",
    "    control.loc[matched_control_idx]\n",
    "], axis=0).sort_index()\n",
    "\n",
    "print(f\"Matched {len(matched_treated_idx)} treated-control pairs using caliper {caliper}\")"
   ],
   "id": "328892309290aaf",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# # Check SMD before/after matching (optional, using TableOne for example)\n",
    "# from tableone import TableOne\n",
    "# matched_df = matched_df.reset_index(drop=True)\n",
    "# print(TableOne(matched_df, columns=X_trim.columns.tolist(), groupby='T', smd=True).tabulate(tablefmt=\"fancy_grid\"))\n",
    "\n"
   ],
   "id": "5727f58803cbe37f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Split matched data back to treated/control\n",
    "matched_treated = matched_df[matched_df['T'] == 1]\n",
    "matched_control = matched_df[matched_df['T'] == 0]\n",
    "\n",
    "ate_matched = (matched_treated['y'].values - matched_control['y'].values).mean()\n",
    "print(f\"ATE from caliper matched sample: {ate_matched:.4f}\")\n"
   ],
   "id": "48a5f9450d93b0c0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "def caliper_matched_ci(matched_treated, matched_control, n_iterations=1000, alpha=0.05, random_seed=random_seed, verbose=True):\n",
    "    \"\"\"\n",
    "    Bootstrap confidence interval for the ATE from caliper matching.\n",
    "\n",
    "    Args:\n",
    "        matched_treated: DataFrame of matched treated units, aligned to matched_control\n",
    "        matched_control: DataFrame of matched control units, aligned\n",
    "        n_iterations: Number of bootstrap samples\n",
    "        alpha: Significance level (default 0.05 for 95% CI)\n",
    "        random_seed: For reproducibility\n",
    "        verbose: Print the CI\n",
    "\n",
    "    Returns:\n",
    "        (lower, upper): bounds of the confidence interval\n",
    "    \"\"\"\n",
    "    np.random.seed(random_seed)\n",
    "    n = len(matched_treated)\n",
    "    ate_estimates = []\n",
    "    for _ in tqdm(range(n_iterations), desc=\"Caliper matching bootstrap\"):\n",
    "        idx = np.random.choice(n, n, replace=True)\n",
    "        ate = (matched_treated['y'].values[idx] - matched_control['y'].values[idx]).mean()\n",
    "        ate_estimates.append(ate)\n",
    "    lower = np.percentile(ate_estimates, 100 * alpha / 2)\n",
    "    upper = np.percentile(ate_estimates, 100 * (1 - alpha / 2))\n",
    "    if verbose:\n",
    "        print(f\"95% Confidence Interval for ATE (Caliper matching): [{lower:.4f}, {upper:.4f}]\")\n",
    "    return lower, upper\n"
   ],
   "id": "231dc51639250d76",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "matching_ci = caliper_matched_ci(matched_treated, matched_control, n_iterations=1000, alpha=0.05, random_seed=random_seed)\n",
   "id": "955fa009c30bfeac",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Reconstruct X for matched treated and controls\n",
    "matched_X_treated = treated.loc[matched_treated_idx, X_trim.columns]\n",
    "matched_X_control = control.loc[matched_control_idx, X_trim.columns]\n",
    "\n",
    "# Stack them together for all matched samples\n",
    "matched_X = pd.concat([matched_X_treated, matched_X_control], axis=0)\n",
    "matched_X = matched_X.reset_index(drop=True)\n",
    "\n",
    "# Build T for all matched samples\n",
    "matched_T = np.concatenate([np.ones(len(matched_X_treated)), np.zeros(len(matched_X_control))])\n",
    "\n",
    "# If you need as DataFrame/Series:\n",
    "matched_T = pd.Series(matched_T, name='T')\n",
    "\n",
    "print(matched_X.shape, matched_T.shape)\n"
   ],
   "id": "bc2281afa8e4880f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "plot_smd_balance(data=pd.concat([matched_X, matched_T], axis=1), covariates= confounders)",
   "id": "e88a3fe7f80f1f74",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "check_overlap(best_model,matched_X,matched_T)",
   "id": "689e3fce6b35c70d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "7273045f63ee578f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "methods = [\"DR\", \"IPW\", \"Matching\",'T_learner']\n",
    "cis = [dr_ci, ipw_ci, matching_ci,t_learner_ci]\n",
    "\n",
    "# Midpoints and error bars\n",
    "midpoints = [(low + high) / 2 for low, high in cis]\n",
    "errors = [(high - low) / 2 for low, high in cis]\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.errorbar(midpoints, methods, xerr=errors, fmt='o', capsize=5, color='teal', ecolor='lightcoral')\n",
    "plt.axvline(0, color='gray', linestyle='--', label=\"Zero Effect\")\n",
    "\n",
    "plt.xlabel(\"Estimated Treatment Effect \")\n",
    "plt.title(\"95% Confidence Intervals for Treatment Effect\")\n",
    "plt.grid(True, axis='x', linestyle='--', alpha=0.4)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "533afe3d8941f952",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "fad897336dfca117",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
